#!/usr/bin/env python3
"""
æ‰¹é‡è®­ç»ƒè„šæœ¬ - è‡ªåŠ¨è®­ç»ƒåŸç‰ˆå’Œæ”¹è¿›ç‰ˆPointNetLKæ¨¡å‹
Batch Training Script - Automatically train both original and improved PointNetLK models
"""

import os
import sys
import subprocess
import argparse
import time
from datetime import datetime


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡è®­ç»ƒåŸç‰ˆå’Œæ”¹è¿›ç‰ˆPointNetLKæ¨¡å‹')
    
    # æ•°æ®é›†è®¾ç½®
    parser.add_argument('--dataset-path', required=True, type=str,
                        help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--dataset-type', default='modelnet', 
                        choices=['modelnet', 'shapenet2', 'kitti', '3dmatch'],
                        help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--num-points', default=1024, type=int,
                        help='ç‚¹äº‘ä¸­çš„ç‚¹æ•°')
    parser.add_argument('--categoryfile', default='', type=str,
                        help='ç±»åˆ«æ–‡ä»¶è·¯å¾„ï¼ˆModelNetéœ€è¦ï¼‰')
    
    # è®­ç»ƒè®¾ç½®
    parser.add_argument('--epochs', default=50, type=int,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', default=16, type=int,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning-rate', default=0.001, type=float,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--device', default='cuda:0', type=str,
                        help='è®¡ç®—è®¾å¤‡')
    
    # è¾“å‡ºè®¾ç½®
    parser.add_argument('--output-dir', default='logs', type=str,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model-prefix', default='model', type=str,
                        help='æ¨¡å‹æ–‡ä»¶å‰ç¼€')
    
    # è®­ç»ƒé€‰é¡¹
    parser.add_argument('--models', default='both', choices=['original', 'improved', 'both'],
                        help='è®­ç»ƒå“ªäº›æ¨¡å‹: original, improved, æˆ– both')
    parser.add_argument('--sequential', action='store_true',
                        help='é¡ºåºè®­ç»ƒï¼ˆé»˜è®¤å¹¶è¡Œè®­ç»ƒï¼‰')
    
    return parser.parse_args()


def build_training_command(model_type, args):
    """æ„å»ºè®­ç»ƒå‘½ä»¤"""
    cmd = [
        'python', 'train_unified.py',
        '--model-type', model_type,
        '--outfile', os.path.join(args.output_dir, f'{args.model_prefix}_{model_type}'),
        '--dataset-path', args.dataset_path,
        '--dataset-type', args.dataset_type,
        '--num-points', str(args.num_points),
        '--epochs', str(args.epochs),
        '--batch-size', str(args.batch_size),
        '--learning-rate', str(args.learning_rate),
        '--device', args.device,
    ]
    
    if args.categoryfile:
        cmd.extend(['--categoryfile', args.categoryfile])
    
    return cmd


def run_training(model_type, args):
    """è¿è¡Œå•ä¸ªæ¨¡å‹çš„è®­ç»ƒ"""
    print(f"\n{'='*60}")
    print(f"å¼€å§‹è®­ç»ƒ {model_type.upper()} æ¨¡å‹")
    print(f"{'='*60}")
    
    start_time = time.time()
    cmd = build_training_command(model_type, args)
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        # è¿è¡Œè®­ç»ƒå‘½ä»¤
        result = subprocess.run(cmd, check=True, capture_output=False)
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"\n{model_type.upper()} æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"è®­ç»ƒæ—¶é—´: {duration:.2f}ç§’ ({duration/60:.2f}åˆ†é’Ÿ)")
        
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ {model_type.upper()} æ¨¡å‹è®­ç»ƒå¤±è´¥!")
        print(f"é”™è¯¯ä»£ç : {e.returncode}")
        return False
    except KeyboardInterrupt:
        print(f"\nâš ï¸  {model_type.upper()} æ¨¡å‹è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­!")
        return False


def run_parallel_training(args):
    """å¹¶è¡Œè®­ç»ƒä¸¤ä¸ªæ¨¡å‹"""
    import threading
    import queue
    
    print("\nğŸš€ å¼€å§‹å¹¶è¡Œè®­ç»ƒä¸¤ä¸ªæ¨¡å‹...")
    
    results = queue.Queue()
    
    def train_worker(model_type):
        success = run_training(model_type, args)
        results.put((model_type, success))
    
    # åˆ›å»ºè®­ç»ƒçº¿ç¨‹
    original_thread = threading.Thread(target=train_worker, args=('original',))
    improved_thread = threading.Thread(target=train_worker, args=('improved',))
    
    # å¯åŠ¨è®­ç»ƒ
    start_time = time.time()
    original_thread.start()
    improved_thread.start()
    
    # ç­‰å¾…å®Œæˆ
    original_thread.join()
    improved_thread.join()
    
    end_time = time.time()
    total_duration = end_time - start_time
    
    # æ”¶é›†ç»“æœ
    training_results = {}
    while not results.empty():
        model_type, success = results.get()
        training_results[model_type] = success
    
    print(f"\n{'='*60}")
    print("å¹¶è¡Œè®­ç»ƒå®Œæˆ!")
    print(f"æ€»æ—¶é—´: {total_duration:.2f}ç§’ ({total_duration/60:.2f}åˆ†é’Ÿ)")
    print(f"åŸç‰ˆæ¨¡å‹: {'âœ… æˆåŠŸ' if training_results.get('original', False) else 'âŒ å¤±è´¥'}")
    print(f"æ”¹è¿›ç‰ˆæ¨¡å‹: {'âœ… æˆåŠŸ' if training_results.get('improved', False) else 'âŒ å¤±è´¥'}")
    print(f"{'='*60}")
    
    return training_results


def run_sequential_training(args):
    """é¡ºåºè®­ç»ƒä¸¤ä¸ªæ¨¡å‹"""
    print("\nğŸ”„ å¼€å§‹é¡ºåºè®­ç»ƒä¸¤ä¸ªæ¨¡å‹...")
    
    total_start_time = time.time()
    results = {}
    
    # è®­ç»ƒåŸç‰ˆæ¨¡å‹
    results['original'] = run_training('original', args)
    
    # è®­ç»ƒæ”¹è¿›ç‰ˆæ¨¡å‹
    results['improved'] = run_training('improved', args)
    
    total_end_time = time.time()
    total_duration = total_end_time - total_start_time
    
    print(f"\n{'='*60}")
    print("é¡ºåºè®­ç»ƒå®Œæˆ!")
    print(f"æ€»æ—¶é—´: {total_duration:.2f}ç§’ ({total_duration/60:.2f}åˆ†é’Ÿ)")
    print(f"åŸç‰ˆæ¨¡å‹: {'âœ… æˆåŠŸ' if results['original'] else 'âŒ å¤±è´¥'}")
    print(f"æ”¹è¿›ç‰ˆæ¨¡å‹: {'âœ… æˆåŠŸ' if results['improved'] else 'âŒ å¤±è´¥'}")
    print(f"{'='*60}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("PointNetLK æ‰¹é‡è®­ç»ƒè„šæœ¬")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ•°æ®é›†è·¯å¾„: {args.dataset_path}")
    print(f"è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ç‚¹äº‘ç‚¹æ•°: {args.num_points}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    if args.models == 'both':
        # è®­ç»ƒä¸¤ä¸ªæ¨¡å‹
        if args.sequential:
            results = run_sequential_training(args)
        else:
            results = run_parallel_training(args)
    elif args.models == 'original':
        # åªè®­ç»ƒåŸç‰ˆæ¨¡å‹
        success = run_training('original', args)
        results = {'original': success}
    elif args.models == 'improved':
        # åªè®­ç»ƒæ”¹è¿›ç‰ˆæ¨¡å‹
        success = run_training('improved', args)
        results = {'improved': success}
    
    # è¾“å‡ºæœ€ç»ˆæ€»ç»“
    print(f"\nğŸ æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆ!")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶ä½ç½®
    if results.get('original', False):
        print(f"ğŸ“ åŸç‰ˆæ¨¡å‹æ–‡ä»¶: {args.output_dir}/{args.model_prefix}_original_best.pth")
    if results.get('improved', False):
        print(f"ğŸ“ æ”¹è¿›ç‰ˆæ¨¡å‹æ–‡ä»¶: {args.output_dir}/{args.model_prefix}_improved_best.pth")


if __name__ == '__main__':
    main() 